---
subtitle: "Een analyse van kansengelijkheid in studiesucces ({{< meta params.model >}})"

# Format and output
output-file: "ch-models.html"

# Parameters
params:
  versie: "1.0"
  succes: "Retentie na 1 jaar"
  model: "Retentie na 1 jaar"
  pd: "Nvt"
  use_synthetic_data: true
  recreate_plots: false
  enrollment_selection: false
  sp: "CMD"
  sp_form: "VT"
---

<!-- Title -->

# Prognosemodel

```{r setup}
#| label: setup
#| include: false

# Current file
current_file <- "ch4-models.qmd"

# Include the _Setup.R file
source("_Setup.R") 

df_model_results <- data.frame(
  model = character(),
  auc = numeric()
)
```

```{r}
#| label: load-data

# Read the data for this study programme
if (params$use_synthetic_data) {
  df_sp_enrollments <- get_sp_enrollments_syn(sp = params$sp,
                                              sp_form = toupper(params$sp_form)) |> 
    mutate(
      ID = as.character(ID),
      INS_Opleiding = as.character(INS_Opleiding),
      INS_Opleidingsvorm = as.character(INS_Opleidingsvorm)
    ) |> 
    mutate(
      INS_Student_UUID_opleiding_vorm = paste(ID, INS_Opleiding, INS_Opleidingsvorm, sep = "_"),
      INS_Opleidingsnaam_huidig = paste(INS_Opleidingsnaam_huidig, "(Synth.)", sep = " ")
    )
} else {
  df_sp_enrollments <- 
    get_lta_studyprogram_enrollments_pin(board = "HHs/Inschrijvingen",
                                         faculty = params$faculty,
                                         studyprogram = params$sp,
                                         sp = params$sp,
                                         sp_form = toupper(params$sp_form),
                                         range = "eerstejaars")
}

# Adjust df_sp_enrollments
df_sp_enrollments <- df_sp_enrollments |> 
  
  # Rearrange the levels
  mutate(across(all_of(names(levels_formal)), 
                ~ factor(.x,
                         levels = levels_formal[[cur_column()]]))) |> 

  # Create a simple success variable
  mutate_retention(succes_model) |>
  
  # Convert the success variable into a factor
  mutate(SUC_Retentie = as.factor(SUC_Retentie)) |> 

  ## Special possibly based on the propaedeutic diploma
  # Filter_pd(pd) |>

  # Make the Dual Study variable a Yes/No variable
  mutate_parallel_sp() |>  

  # Remove INS_Aantal_inschrijvingen
  select(-INS_Aantal_inschrijvingen) 

## Adjust the levels of sensitive variables
for (i in sensitive_formal_variables){
  df_sp_enrollments <- df_sp_enrollments |>
    mutate_levels(
      i,
      list(levels_formal[[i]])
    )
}
  
# B Huidtherapie: Filter on only students with a grade number (selection)
if (sp == "HDT") {
  df_sp_enrollments <- df_sp_enrollments |> 
    filter(!is.na(RNK_Rangnummer)) 
} 

```

```{r}
#| label: select-inspect-data

list_select <- get_list_select(df_variables, "VAR_Formal_variable")

# B Huidtherapie: add the variable RNK_Rangnummer unless it is HDT
if (sp == "HDT") {
  list_select <- c(list_select, "RNK_Rangnummer")
}

# Create a mapping with formal and simple maes
name_mapping_list <- setNames(df_variables$VAR_Simple_variable, df_variables$VAR_Formal_variable)

# Create a subset
df_sp_enrollments <- df_sp_enrollments |>
  
  # Select the relevant variables
  select(all_of(list_select)) |>
  
  # Rename variables for more readable names
  rename_with(~ name_mapping_list[.x], .cols = everything()) |> 
  
  # Adjust CBS_APCG_tf to a factor
  mutate_apcg() |>

  # Indicate where missing numbers are in VO
  mutate_grade_preeducation() |>
  
  # Remove variables, where there is only 1 value
  select(where(~ n_distinct(.) > 1)) |>
  
  # Sort
  arrange(Collegejaar, ID)

df_sp_enrollments <- df_sp_enrollments |> 
  sort_distinct()

```

```{r}
#| label: tbl-summarizy-missing-after
#| tbl-cap: "Kwaliteit van de data na bewerkingen (gesorteerd op missende waarden)"

# Edit the data
df_sp_enrollments <- df_sp_enrollments |> 
  
  # Imputate all numeric variables with the mean
  mutate(across(where(is.numeric), ~ ifelse(
    is.na(.x),
    mean(.x, na.rm = TRUE),
    .x
  ))) |>
  
  # Convert character variables to factor
  mutate(across(where(is.character), as.factor)) |> 
  
  # Convert logical variables to 0 or 1
  mutate(across(where(is.logical), as.integer)) |>
  
  # Fill in factors missing values with “Unknown”
  mutate(across(where(is.factor), ~ suppressWarnings(
    forcats::fct_explicit_na(.x, na_level = "Onbekend")
  ))) |> 
  
  # Rearrange the columns so that Retentie is in front
  select(Retentie, everything()) 

```


```{r}
#| label: split-data

set.seed(0821)

# Split the data into 3 parts: 60%, 20% and 20%
splits      <- initial_validation_split(df_sp_enrollments,
                                        strata = Retentie,
                                        prop = c(0.6, 0.2))

# Create three sets: a training set, a test set and a validation set
df_retention_train      <- training(splits)
df_retention_test       <- testing(splits)
df_retention_validation <- validation_set(splits)

# Create a resample set based on 10 folds (default)
df_retention_resamples  <- vfold_cv(df_retention_train, strata = Retentie)
```

```{r}
#| label: lr-mod
#| code-fold: false

# Build the model: logistic regression
lr_mod <- 
  logistic_reg(penalty = tune(), mixture = 1) |> 
  set_engine("glmnet")
```

```{r}
#| label: lr-recipe
#| code-fold: false

# Build the recipe: logistic regression
lr_recipe <- 
  recipe(Retentie ~ ., data = df_retention_train) |>  
  update_role(ID, new_role = "ID") |>           # Set the student ID as an ID variable
  step_rm(ID, Collegejaar) |>                   # Remove ID and college year from the model
  step_unknown(Studiekeuzeprofiel, 
               new_level = "Onbekend skp") |>   # Add unknown skp
  step_dummy(all_nominal_predictors()) |>       # Create dummy variables from categorical variables
  step_zv(all_predictors()) |>                  # Remove zero values
  step_normalize(all_numeric_predictors())      # Center and scale numeric variables

```

```{r}
#| label: lr-workflow
#| code-fold: false

# Create the workflow: logistic regression
lr_workflow <- 
  workflow() |>         # Create a workflow
  add_model(lr_mod) |>  # Add the model
  add_recipe(lr_recipe) # Add the recipe

```

```{r}
#| label: lr-reg-grid
#| code-fold: false

# Create a grid: logistic regression
lr_reg_grid <- tibble(penalty = 10 ^ seq(-4, -1, length.out = 30))

# Train and tune the model: logistic regression
lr_res <- 
  lr_workflow |> 
  tune_grid(df_retention_validation,
            grid = lr_reg_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))

```

```{r}
#| label: lr-best
#| code-fold: false

# Select the best model: logistic regression
lr_best <- 
  lr_res |> 
  collect_metrics() |> 
  filter(mean == max(mean)) |>
  slice(1) 
```

```{r}
#| label: lr-auc
#| code-fold: false

# Collect the predictions and evaluate the model (AUC/ROC): logistic regression
lr_auc <- 
  lr_res |> 
  collect_predictions(parameters = lr_best) |> 
  roc_curve(Retentie, .pred_FALSE) |> 
  mutate(model = "Logistisch Regressie")
```

```{r}
#| label: lr-auc-highest

# Determine the AUC of the best model
lr_auc_highest   <-
  lr_res |>
  collect_predictions(parameters = lr_best) |> 
  roc_auc(Retentie, .pred_FALSE)

# Add model name and AUC df_model_results
df_model_results <- 
  df_model_results |>
  add_row(model = "Logistic Regression", auc = lr_auc_highest$.estimate)

```

<!-- MODEL II: Random Forest -->

```{r}
#| label: cores

# Determine the number of cores
cores <- parallel::detectCores()

```

```{r}
#| label: rf-mod
#| code-fold: false

# Build the model: random forest

rf_mod <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) |> 
  set_engine("ranger", num.threads = cores) |> 
  set_mode("classification")
```


```{r}
#| label: rf-recipe
#| code-fold: false

# Create the recipe: random forest
rf_recipe <- 
  recipe(Retentie ~ ., data = df_retention_train) |> 
  step_unknown(Studiekeuzeprofiel, 
               new_level = "Onbekend skp") |>   # Add unknown skp
  step_rm(ID, Collegejaar)                      # Remove ID and Collegejaar from the model
```

```{r}
#| label: rf-workflow
#| code-fold: false

# Create the workflow: random forest
rf_workflow <- 
  workflow() |> 
  add_model(rf_mod) |> 
  add_recipe(rf_recipe)

```


```{r}
#| label: rf-tune
#| code-fold: false

# Show the parameters that can be tuned
rf_mod

# Extract the parameters being tuned
extract_parameter_set_dials(rf_mod)

# Determine the seed
set.seed(2904)

# Build the grid: random forest
rf_res <- 
  rf_workflow |> 
  tune_grid(df_retention_validation,
            grid = 25,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))
```

```{r}
#| label: tbl-rf-results
#| tbl-cap: "Model performance voor random forest"
#| code-fold: false

# Show the best models
rf_res |> 
  show_best(metric = "roc_auc", n = 15) |> 
  mutate(mean = round(mean, 6)) |>
  knitr::kable(col.names = c("Mtry", 
                             "Min. aantal", 
                             "Metriek",
                             "Estimator",
                             "Gemiddelde",
                             "Aantal",
                             "SE",
                             "Configuratie"))

```

```{r}
#| label: rf-best
#| code-fold: false

# Select the best model
rf_best <- 
  rf_res |> 
  select_best(metric = "roc_auc")

```


```{r}
#| label: fig-rf-auc
#| fig-cap: "ROC curve voor random forest"
 
# Determine the AUC/ROC curve
rf_auc <- 
  rf_res |> 
  collect_predictions(parameters = rf_best) |> 
  roc_curve(Retentie, .pred_FALSE) |> 
  mutate(model = "Random Forest")

# Determine the AUC of the best model
rf_auc_highest   <-
  rf_res |>
  collect_predictions(parameters = rf_best) |> 
  roc_auc(Retentie, .pred_FALSE)

# Add model name and AUC to df_model_results
df_model_results <- 
  df_model_results |>
  add_row(model = "Random Forest", 
          auc = rf_auc_highest$.estimate)

```

<!-- Final Fit -->

```{r}
#| label: best-model-auc-roc

# Determine which of the models is best based on highest AUC/ROC
df_model_results <- df_model_results |>
  mutate(number = row_number()) |> 
  mutate(best = ifelse(auc == max(auc), TRUE, FALSE)) |> 
  arrange(number)

# Determine the best model
best_model     <- df_model_results$model[df_model_results$best == TRUE]
best_model_auc <- round(df_model_results$auc[df_model_results$best == TRUE], 4)
```

```{r}
#| label: last-mod
#| code-fold: false

# Test the developed model on the test set
# Determine the optimal parameters

# Build the final models
last_lr_mod <-
  logistic_reg(penalty = lr_best$penalty,
               mixture = 1) |>
  set_engine("glmnet") |>
  set_mode("classification")

last_rf_mod <-
  rand_forest(mtry = rf_best$mtry,
              min_n = rf_best$min_n,
              trees = 1000) |>
  set_engine("ranger", num.threads = cores, importance = "impurity") |>
  set_mode("classification")

```

```{r}
#| label: last-workflow
#| code-fold: false

# Update the workflows
last_lr_workflow <- 
  lr_workflow |> 
  update_model(last_lr_mod)

last_rf_workflow <- 
  rf_workflow |> 
  update_model(last_rf_mod)

```

```{r}
#| label: last-fit
#| code-fold: false

# Perform the final fit
set.seed(2904)

# Make a final fit for both models so we can save it for later use
last_fit_lr <- 
  last_lr_workflow |> 
  last_fit(splits)

last_fit_rf <- 
  last_rf_workflow |> 
  last_fit(splits)

last_fits <- list(last_fit_lr, last_fit_rf) |> 
  set_names(c("Logistic Regression", "Random Forest"))

# Determine which model is best
if (best_model == "Logistic Regression") {
  last_fit <- last_fit_lr
} else if (best_model == "Random Forest") {
  last_fit <- last_fit_rf
}

# Keep results, model results and associated data
fittedmodels_outputpath <- get_model_outputpath(mode = "last-fits")
saveRDS(last_fits, file = fittedmodels_outputpath)

modelresults_outputpath <- get_model_outputpath(mode = "modelresults")
saveRDS(df_model_results, file = modelresults_outputpath)

data_outputpath <- get_model_outputpath(mode = "data")
saveRDS(df_sp_enrollments, file = data_outputpath)

```
